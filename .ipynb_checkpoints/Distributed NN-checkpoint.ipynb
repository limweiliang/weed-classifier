{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import cv2\n",
    "import numpy as np\n",
    "import tensorflow_datasets as tfds\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn\n",
    "import math\n",
    "import tensorflow_addons as tfa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "RANDOM_STATE = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow_datasets\\core\\dataset_builder.py:622: get_single_element (from tensorflow.python.data.experimental.ops.get_single_element) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.data.Dataset.get_single_element()`.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow_datasets\\core\\dataset_builder.py:622: get_single_element (from tensorflow.python.data.experimental.ops.get_single_element) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.data.Dataset.get_single_element()`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(17509, 256, 256, 3) (17509,)\n"
     ]
    }
   ],
   "source": [
    "ds = tfds.load('deep_weeds', batch_size = -1, as_supervised= True)\n",
    "images, labels = ds['train'] # Type: EagerTensor\n",
    "\n",
    "# Shuffle the dataset\n",
    "images = tf.random.shuffle(images, seed=RANDOM_STATE)\n",
    "labels = tf.random.shuffle(labels, seed=RANDOM_STATE)\n",
    "\n",
    "print(images.shape, labels.shape)\n",
    "\n",
    "img_0 = tf.gather_nd(images, tf.where(labels == 0)).numpy()\n",
    "img_1 = tf.gather_nd(images, tf.where(labels == 1)).numpy()\n",
    "img_2 = tf.gather_nd(images, tf.where(labels == 2)).numpy()\n",
    "img_3 = tf.gather_nd(images, tf.where(labels == 3)).numpy()\n",
    "img_4 = tf.gather_nd(images, tf.where(labels == 4)).numpy()\n",
    "img_5 = tf.gather_nd(images, tf.where(labels == 5)).numpy()\n",
    "img_6 = tf.gather_nd(images, tf.where(labels == 6)).numpy()\n",
    "img_7 = tf.gather_nd(images, tf.where(labels == 7)).numpy()\n",
    "img_8 = tf.gather_nd(images, tf.where(labels == 8)).numpy()\n",
    "\n",
    "\n",
    "label_0 = tf.gather_nd(labels, tf.where(labels == 0)).numpy()\n",
    "label_1 = tf.gather_nd(labels, tf.where(labels == 1)).numpy()\n",
    "label_2 = tf.gather_nd(labels, tf.where(labels == 2)).numpy()\n",
    "label_3 = tf.gather_nd(labels, tf.where(labels == 3)).numpy()\n",
    "label_4 = tf.gather_nd(labels, tf.where(labels == 4)).numpy()\n",
    "label_5 = tf.gather_nd(labels, tf.where(labels == 5)).numpy()\n",
    "label_6 = tf.gather_nd(labels, tf.where(labels == 6)).numpy()\n",
    "label_7 = tf.gather_nd(labels, tf.where(labels == 7)).numpy()\n",
    "label_8 = tf.gather_nd(labels, tf.where(labels == 8)).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pre-Processing\n",
    "def combine(label):\n",
    "    if label == 0:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "vcombine = np.vectorize(combine)\n",
    "    \n",
    "def add_grey_grad(img):\n",
    "    org_img = img\n",
    "    #img = img.astype(np.float32)\n",
    "    #img = tf.expand_dims(img, axis = 0)\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "    sobelx = cv2.Sobel(gray,cv2.CV_64F,1,0,ksize=5)\n",
    "    sobely = cv2.Sobel(gray,cv2.CV_64F,0,1,ksize=5)\n",
    "    dmag = np.sqrt(sobelx**2 + sobely**2)\n",
    "\n",
    "    #Normalize to 0 - 255\n",
    "    im_max = np.min(dmag)\n",
    "    im_min = np.max(dmag)\n",
    "    out = ((dmag - im_min) / (im_max - im_min)) * 255\n",
    "    out = np.expand_dims(out.astype(np.uint8), axis = 0)\n",
    "    out = cv2.GaussianBlur(out,(3,3),0)[0]\n",
    "    out = np.expand_dims(out.astype(np.uint8), axis = 2)\n",
    "    \n",
    "    gray = np.expand_dims(gray.astype(np.uint8), axis = 2)\n",
    "    \n",
    "    org_img = np.concatenate([org_img,gray,out],-1)\n",
    "    return org_img\n",
    "\n",
    "v_grey_grad = np.vectorize(add_grey_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "concatenated_images_pre = np.concatenate((img_0, img_1, img_2, img_3, img_4, img_5, img_6, img_7, img_8), axis=0)\n",
    "concatenated_label = np.concatenate((label_0, label_1, label_2, label_3, label_4, label_5, label_6, label_7, label_8), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "concatenated_images = []\n",
    "\n",
    "for i in concatenated_images_pre:\n",
    "    concatenated_images.append(add_grey_grad(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "concatenated_label = vcombine(concatenated_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "del concatenated_images_pre\n",
    "del img_0\n",
    "del img_1\n",
    "del img_2\n",
    "del img_3\n",
    "del img_4\n",
    "del img_6\n",
    "del img_7\n",
    "del img_8\n",
    "\n",
    "del label_0\n",
    "del label_1\n",
    "del label_2\n",
    "del label_3\n",
    "del label_4\n",
    "del label_5\n",
    "del label_6\n",
    "del label_7\n",
    "del label_8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import datasets, layers, models, regularizers, Input\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X, test_X, train_y, test_y = train_test_split(concatenated_images, concatenated_label, test_size=0.2, random_state=0)\n",
    "\n",
    "print(train_X.shape)\n",
    "print(train_y.shape)\n",
    "print(test_X.shape)\n",
    "print(test_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = Input(shape = (256,256,5), name = \"Original_Image\")\n",
    "flip = layers.RandomFlip(\"horizontal_and_vertical\")(inputs)\n",
    "rotate = layers.RandomRotation((-0.5,0.5), fill_mode = \"nearest\")(flip)\n",
    "rescale = layers.Rescaling(1/255)(rotate)\n",
    "\n",
    "x = layers.Conv2D(16, (3,3), padding = \"same\", strides = 2)(rescale)\n",
    "x = layers.Conv2D(16, (3,3), padding = \"same\", strides = 2)(x)\n",
    "x = layers.BatchNormalization()(x)\n",
    "x = layers.ReLU()(x)\n",
    "block_1_output = layers.MaxPool2D(3,3)(x)\n",
    "\n",
    "x = layers.Flatten()(block_1_output)\n",
    "x = layers.Dense(128)(x)\n",
    "x = layers.Dropout(0.5)(x)\n",
    "outputs = layers.Dense(1, activation = 'sigmoid')(x)\n",
    "\n",
    "model = tf.keras.Model(inputs, outputs, name=\"Distributed_Model\")\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.Adam(learning_rate= 0.005)\n",
    "\n",
    "\n",
    "model.compile(optimizer=optimizer,\n",
    "              loss= 'categorical_crossentropy',\n",
    "              metrics=[\"Precision\", \"Recall\",'accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EarlyStop = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=50, restore_best_weights=True , verbose = 1)\n",
    "\n",
    "#Constant learning rate for first N epochs then it decreases exponentially\n",
    "# def scheduler(epoch, lr):\n",
    "#   if epoch < 65:\n",
    "#     return lr\n",
    "#   else:\n",
    "#     return lr * tf.math.exp(-0.1/5)\n",
    "\n",
    "# lr_callback = tf.keras.callbacks.LearningRateScheduler(scheduler)\n",
    "\n",
    "reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.6,\n",
    "                              patience=5, cooldown=10, verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist = model.fit(train_ds, epochs=200,\n",
    "                     validation_data= validation_ds, callbacks=[EarlyStop, reduce_lr],batch_size = BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = hist.history['accuracy']\n",
    "val_acc = hist.history['val_accuracy']\n",
    "loss = hist.history['loss']\n",
    "val_loss = hist.history['val_loss']\n",
    "precision = hist.history['precision']\n",
    "val_precision = hist.history['val_precision']\n",
    "recall = hist.history['recall']\n",
    "val_recall = hist.history['val_recall']\n",
    "\n",
    "# Plot the graph manually\n",
    "epochs = range(len(loss))\n",
    "\n",
    "plt.figure(figsize=(25, 25))\n",
    "plt.subplot(4, 1, 1)\n",
    "plt.plot(epochs, loss, 'r', label='Training Loss')\n",
    "plt.plot(epochs, val_loss, 'b', label='Validation Loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(4, 1, 2)\n",
    "plt.plot(epochs, acc, 'r', label='Training Accuracy')\n",
    "plt.plot(epochs, val_acc, 'b', label='Validation Accuracy')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(4, 1, 3)\n",
    "plt.plot(epochs, precision, 'r', label='Training Precision')\n",
    "plt.plot(epochs, val_precision, 'b', label='Validation Precision')\n",
    "plt.title('Training and validation Precision')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(4, 1, 4)\n",
    "plt.plot(epochs, recall, 'r', label = \"Training Recall\")\n",
    "plt.plot(epochs, val_recall, 'b', label='Validation Recall')\n",
    "plt.title('Training and validation Recall')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(validation_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
